# -*- coding: utf-8 -*-
"""mnist_digit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tEa3MXlHU4aHe2VsPkzRFuZNXxIXpzPX
"""

# -*- coding: utf-8 -*-
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2

# Load MNIST dataset
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize data
x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

# Reshape for CNN: (samples, 28, 28, 1)
IMG_SIZE = 28
x_trainr = x_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)
x_testr = x_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)

# Define CNN model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D

model = Sequential()
model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation("relu"))
model.add(Dense(32))
model.add(Activation("relu"))
model.add(Dense(10))
model.add(Activation("softmax"))

model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
model.summary()

# Data augmentation with proper validation split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    validation_split=0.3,  # internal validation split
    rotation_range=10,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1
)

## The below code is to what augmenattion is doing

# for i, (images, labels) in enumerate(datagen.flow(x_trainr, y_train, batch_size=1, subset='training')):
#     plt.imshow(images[0].reshape(28, 28), cmap='gray')
#     plt.title(f"Augmented Example for Label: {labels[0]}")
#     plt.axis('off')
#     plt.show()
#     if i == 4:
#         break  # Show 5 examples and stop


# Create training and validation generators
train_generator = datagen.flow(x_trainr, y_train, batch_size=32, subset='training')
val_generator = datagen.flow(x_trainr, y_train, batch_size=32, subset='validation')

# Train the model
model.fit(train_generator, validation_data=val_generator, epochs=5)

# Evaluate on test data
test_loss, test_acc = model.evaluate(x_testr, y_test)
print("Test loss:", test_loss)
print("Test accuracy:", test_acc)

# Predict on a sample test image
predictions = model.predict(x_testr)
print("Prediction for first test image:", np.argmax(predictions[0]))

plt.imshow(x_test[0], cmap='gray')
plt.title(f"True Label: {y_test[0]}")
plt.show()

# ================================
# üîç Predict on external image
# ================================
def preprocess_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale
    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)  # Resize
    img = cv2.bitwise_not(img)  # Invert colors (optional, depends on your image)
    img = tf.keras.utils.normalize(img, axis=1)  # Normalize like training
    img = np.array(img).reshape(-1, 28, 28, 1)  # Reshape to match input
    return img

external_img = preprocess_image("3.png")

# Predict
external_pred = model.predict(external_img)
print("Prediction for external image:", np.argmax(external_pred))

# Visualize external image
plt.imshow(external_img[0].reshape(28, 28), cmap='gray')
plt.title(f"Predicted Label: {np.argmax(external_pred)}")
plt.show()

model.save("mnist_model.h5")

from google.colab import files
files.download("mnist_model.h5")

